{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Due: Friday, 3 December, 2021 at 17:00 CET*\n",
    "\n",
    "For the first assignment of the course Applications of Machine Learning (INFOB3APML), you will learn to use decision tree, random forest, and isolation forest to detect an outlier class. The objectives of this assignment are:\n",
    "- use the supervised classification algorithms to classify outliers in real-life data sets\n",
    "- use the unsupervised outlier detection algorithms to detect outliers in real-life data sets\n",
    "- perform cross validation and fine-tune the model parameters of each algorithm\n",
    "- calculate model performance (e.g., accuracy, recall, precision, f1)\n",
    "- design experiments to compare performance of algorithms\n",
    "- reflect on the difference between different models\n",
    "\n",
    "\n",
    "This assignment includes three algorithms: DT, RF, and IF. The first task is to perform data exploration. In Task 2-4, you will use the three algorithms to classify outliers, respectively. In Task 5, you will compare the algorithms and evaluate their results. Please note that Task 2-4 have the following structure:\n",
    "1. First, find the library (e.g., sklearn examples) and try out the algorithm by simply training the model on the training data (do not consider any parameters or cross validation just yet); \n",
    "2. Train the model with the training data by using cross validation and find the best parameter setting for the parameters of interest;\n",
    "3. Report the average test accuracy, recall, precision, and F1 scores of all validationn sets;\n",
    "4. Finally, test the optimal model that has the best fitting parameters on your held-out test data, and report its accuracy, precision, recall, and F1. \n",
    "\n",
    "Note that, in Task 5, you will need all the calculated accuracy, precision, recall and F1 measures from previous tasks. Make sure you save these to a list or dictionary so you can easily evaluate and compare the results. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Task 1: Exploring the data set\n",
    " \n",
    " \n",
    "\n",
    "### Data set: Bank Marketing\n",
    "\n",
    "\n",
    "Import the file *dataBank-additional-full_normalised.csv* to load the preprocessed data set. \"*The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed.*\"\n",
    "\n",
    "\n",
    "Use the column \"label\" as the response variable. The instances labeled with 1 are the \"outliers\", in this case the class we would like to detect accurately; the instance labeled with 0 are the inliers. \n",
    "\n",
    "\n",
    "The original data description can be found via the link here below. You will also find some explainations regarding the features under the section \"Attribute Information\".  \n",
    "https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import data\n",
    "data = pd.read_csv('./dataBank-additional-full_normalised.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1. Exploratory data analysis\n",
    "\n",
    "For the data set, create 2-3 figures and tables that will help you understand the data. \n",
    "\n",
    "\n",
    "During the data exploration, you, as a team, are trying to get an impression about the data. You will create figures and/or tables that help you to get to know the data. While exploring the data, you may also consider answering the following questions, which may help you understand the data better. For example, \n",
    "\n",
    "- How many instances are there in each class? Are the classes imbalanced?\n",
    "- How many variables are in the data? What is the data type and the distribution of each variable? \n",
    "- Are the variables informative?\n",
    "- Are any pair of the potential predictor variables highly correlated?\n",
    "- (Should the variables be normalized or not?)\n",
    "- (Any relevant, useful preprocessing steps that may be taken?)\n",
    "\n",
    "#### Tips: \n",
    "\n",
    "Make sure to at least check the data type of each variable and to understand the distribution of each variable, especially the response variable. \n",
    "\n",
    "Try to find out what factors seem to determine whether an instance is an outlier or not. What do you conclude?\n",
    "\n",
    "*For creating data visualizations, you may consider using the matplot library and visit the [matplot gallery](https://matplotlib.org/stable/gallery/index.html) for inspiration (e.g., histograms for distribution, or heatmaps for feature correlation).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                age  job=housemaid  job=services    job=admin.  \\\n",
      "count  41188.000000   41188.000000  41188.000000  41188.000000   \n",
      "mean       0.284248       0.025736      0.096363      0.253035   \n",
      "std        0.128657       0.158348      0.295092      0.434756   \n",
      "min        0.000000       0.000000      0.000000      0.000000   \n",
      "25%        0.185185       0.000000      0.000000      0.000000   \n",
      "50%        0.259259       0.000000      0.000000      0.000000   \n",
      "75%        0.370370       0.000000      0.000000      1.000000   \n",
      "max        1.000000       1.000000      1.000000      1.000000   \n",
      "\n",
      "       job=blue-collar  job=technician   job=retired  job=management  \\\n",
      "count     41188.000000    41188.000000  41188.000000    41188.000000   \n",
      "mean          0.224677        0.163713      0.041760        0.070992   \n",
      "std           0.417375        0.370019      0.200042        0.256814   \n",
      "min           0.000000        0.000000      0.000000        0.000000   \n",
      "25%           0.000000        0.000000      0.000000        0.000000   \n",
      "50%           0.000000        0.000000      0.000000        0.000000   \n",
      "75%           0.000000        0.000000      0.000000        0.000000   \n",
      "max           1.000000        1.000000      1.000000        1.000000   \n",
      "\n",
      "       job=unemployed  job=self-employed  ...      previous  \\\n",
      "count    41188.000000       41188.000000  ...  41188.000000   \n",
      "mean         0.024619           0.034500  ...      0.024709   \n",
      "std          0.154962           0.182513  ...      0.070700   \n",
      "min          0.000000           0.000000  ...      0.000000   \n",
      "25%          0.000000           0.000000  ...      0.000000   \n",
      "50%          0.000000           0.000000  ...      0.000000   \n",
      "75%          0.000000           0.000000  ...      0.000000   \n",
      "max          1.000000           1.000000  ...      1.000000   \n",
      "\n",
      "       poutcome=nonexistent  poutcome=failure  poutcome=success  emp.var.rate  \\\n",
      "count          41188.000000      41188.000000      41188.000000  41188.000000   \n",
      "mean               0.863431          0.103234          0.033335      0.725393   \n",
      "std                0.343396          0.304268          0.179512      0.327283   \n",
      "min                0.000000          0.000000          0.000000      0.000000   \n",
      "25%                1.000000          0.000000          0.000000      0.333333   \n",
      "50%                1.000000          0.000000          0.000000      0.937500   \n",
      "75%                1.000000          0.000000          0.000000      1.000000   \n",
      "max                1.000000          1.000000          1.000000      1.000000   \n",
      "\n",
      "       cons.price.idx  cons.conf.idx     euribor3m   nr.employed         class  \n",
      "count    41188.000000   41188.000000  41188.000000  41188.000000  41188.000000  \n",
      "mean         0.535723       0.430854      0.677237      0.769134      0.112654  \n",
      "std          0.225581       0.193648      0.393210      0.273163      0.316173  \n",
      "min          0.000000       0.000000      0.000000      0.000000      0.000000  \n",
      "25%          0.340608       0.338912      0.160961      0.512287      0.000000  \n",
      "50%          0.603274       0.376569      0.957379      0.859735      0.000000  \n",
      "75%          0.698753       0.602510      0.980957      1.000000      0.000000  \n",
      "max          1.000000       1.000000      1.000000      1.000000      1.000000  \n",
      "\n",
      "[8 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create an overview of the data\n",
    "print(data.describe())\n",
    "# print(data.columns)\n",
    "\n",
    "\n",
    "# TODO: plot figure(s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Creating Train and Test data sets\n",
    "\n",
    "Create a training and a held-out test data set. *Later in Task 2-4, the training data will be used to perform cross-validation. The held-out test data will be used to evaluate the performance of the selected models.*\n",
    "\n",
    "Choose the size of your test data and motivate your choice when you discuss the experiment setup in your report. \n",
    "\n",
    "Tips: \n",
    "\n",
    "*You may use the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) class provided by sklearn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable ellipsis object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-01fa9432c35c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[1;31m# TODO: create training data and held-out test data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m \u001B[0mX_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_heldout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_heldout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m...\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot unpack non-iterable ellipsis object"
     ]
    }
   ],
   "source": [
    "# import method to make a train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# copy data\n",
    "df = data.copy()\n",
    "\n",
    "# create X and y\n",
    "features = ['age', 'job=housemaid', 'job=services', 'job=admin.', 'job=blue-collar',\n",
    "       'job=technician', 'job=retired', 'job=management', 'job=unemployed',\n",
    "       'job=self-employed', 'job=unknown', 'job=entrepreneur', 'job=student',\n",
    "       'marital=married', 'marital=single', 'marital=divorced',\n",
    "       'marital=unknown', 'education=basic.4y', 'education=high.school',\n",
    "       'education=basic.6y', 'education=basic.9y',\n",
    "       'education=professional.course', 'education=unknown',\n",
    "       'education=university.degree', 'education=illiterate', 'default=0',\n",
    "       'default=unknown', 'default=1', 'housing=0', 'housing=1',\n",
    "       'housing=unknown', 'loan=0', 'loan=1', 'loan=unknown',\n",
    "       'contact=cellular', 'month=may', 'month=jun', 'month=jul', 'month=aug',\n",
    "       'month=oct', 'month=nov', 'month=dec', 'month=mar', 'month=apr',\n",
    "       'month=sep', 'day_of_week=mon', 'day_of_week=tue', 'day_of_week=wed',\n",
    "       'day_of_week=thu', 'day_of_week=fri', 'duration', 'campaign', 'pdays',\n",
    "       'previous', 'poutcome=nonexistent', 'poutcome=failure',\n",
    "       'poutcome=success', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "       'euribor3m', 'nr.employed']\n",
    "X = df[features]\n",
    "y = df[['class']]\n",
    "\n",
    "\n",
    "\n",
    "# TODO: create training data and held-out test data\n",
    "X_, X_heldout, y_, y_heldout = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Decision Trees\n",
    "\n",
    "### 2.1 Decision Tree\n",
    "\n",
    "Use the basic [Decision Tree](http://scikit-learn.org/stable/modules/tree.html#tree) library in sklearn to learn a decision tree model by fitting the full training data.\n",
    "\n",
    "Show/plot the tree diagram and also plot the feature importances. \n",
    "What do you observe?\n",
    "\n",
    "\n",
    "#### Tips:\n",
    "\n",
    "To show the tree diagram, you may use the graphviz library or use the plot_tree function, see https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# TODO: learn a decision tree using default parameters\n",
    "cl = ...\n",
    "cl.fit(...)\n",
    "\n",
    "# TODO: plot the tree\n",
    "\n",
    "\n",
    "# TODO: plot the feature importances\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Confusion Matrix and Accuracy\n",
    "\n",
    "Compute the *confusion matrix* and *accuracy* of the tree using the held-out data set. Moreover, also compute the *recall*, *precision*, and *F1-score* of the tree. \n",
    "\n",
    "\n",
    "For this part, you can either implement your own functions or use the following scikit-learn libraries.  \n",
    "- [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)\n",
    "- [accuracy score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "- [recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)\n",
    "- [precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "- [f1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
    "- [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report)\n",
    "\n",
    "\n",
    "Reflect on the performance of the model and be aware of the difference between *accuracy* and *F1-score*. How good is this decision tree model for outlier detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# use the model to make predictions for the test data set\n",
    "y_pred = cl.predict(X_heldout)\n",
    "\n",
    "# TODO: compute accuracy, recall, precision, and f1 score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Features to Tree  (optional)\n",
    "\n",
    "Use the training data to re-fit a new decision tree with the parameter max_depth set to 4. Show the tree diagram and also plot the feature importances. \n",
    "\n",
    "Recalculate the performance of this simpler model. \n",
    "\n",
    "What do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: learn a decision tree with maximal depth 4\n",
    "\n",
    "\n",
    "# TODO: plot the tree\n",
    "\n",
    "\n",
    "# use the model to make predictions for the test data set\n",
    "\n",
    "\n",
    "# TODO: compute accuracy, recall, precision, and f1 score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Cross validation (optional)\n",
    "\n",
    "The code example shown here below uses the [kfold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) method to implement 10-fold cross-validation. Moreover, it uses the cross validation to explore how the max_depth influences the model performance. It keeps track of the validation accuracy scores and F1-scores across the 10 folds. \n",
    "\n",
    "\n",
    "Now, change the code to also compute the recall and precision. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# create 10-fold cross-validation\n",
    "nk = 10\n",
    "kf = KFold(n_splits=nk, random_state=0, shuffle=True)\n",
    "\n",
    "# Search the parameter among the following\n",
    "C = np.arange(2, 10,)\n",
    "\n",
    "\n",
    "# init acc\n",
    "acc = np.zeros((nk , 8))\n",
    "# init f1\n",
    "f1 = np.zeros((nk , 8))\n",
    "i = 0\n",
    "for train_index , val_index in kf.split(X_):\n",
    "    X_t, X_val = X_.iloc[train_index], X_.iloc[val_index]\n",
    "    y_t, y_val = y_.iloc[train_index], y_.iloc[val_index]\n",
    "    j = 0\n",
    "    for c in C:\n",
    "        dt = tree.DecisionTreeClassifier(min_samples_leaf = 1, max_depth = c)\n",
    "        dt.fit(X_t, y_t)\n",
    "        yhat = dt.predict(X_val)\n",
    "        acc[i][j] = accuracy_score(yhat , y_val)\n",
    "        f1[i][j] = f1_score(yhat , y_val)\n",
    "        j = j + 1\n",
    "    i = i + 1\n",
    "    \n",
    "print('Mean accuracy: ' + str(np.mean(acc , axis = 0)))\n",
    "print('Selected model index: ' + str(np.argmax(np.mean(acc , axis = 0))))\n",
    "\n",
    "print('Mean F1: ' + str(np.mean(f1 , axis = 0)))\n",
    "print('Selected model index: ' + str(np.argmax(np.mean(f1 , axis = 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Tree Tuning\n",
    "\n",
    "\n",
    "\n",
    "The built-in decision tree algorithm you are using has several parameters which you can tune (e.g., *max_depth* and *min_samples_leaf*). Use 10-fold cross-validation (e.g., reuse the code of task 2.4 and adapt the code for two parameters), show how the choice of these parameters affects performance. \n",
    "\n",
    "\n",
    "#### Tips: \n",
    "Make a decision on the range of values that you would try for the two parameters and discuss your choice in the experiment setup section.\n",
    "\n",
    "Here is a guide that helps you to build the experiment.\n",
    "First, reuse the code of task 2.4 and show how max_depth affects train and test accuracy. On a single axis, plot train and test accuracy as a function of max_depth. Use a red line to show test accuracy and a blue line to show train accuracy. (Do not use your held-out test data yet). \n",
    "\n",
    "Second, show how test accuracy relates to both max_depth and min_samples_leaf. Specifically, create a 3-D plot where the x-axis is max_depth, the y-axis is min_samples_leaf, and the z-axis shows accuracy. What combination of max_depth and min-samples_leaf achieves the highest F1 score? How sensitive are the results to these two parameters? \n",
    "\n",
    "Finally, select the best-performing decision tree (i.e., the one that achieved the highest cross-validated performance) and report the performance of the fitted model on the held-out test data -- how does it compare to the cross-validated F1 score?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create 10-fold cross-validation\n",
    "\n",
    "# TODO: set the search space of the parameters\n",
    "\n",
    "# TODO: learn an optimal decision tree model\n",
    "\n",
    "# TODO: create 2D or 3D plot that shows how the selected parameters affect the performance. \n",
    "\n",
    "# TODO: compute the performance of the model on your held-out test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Random Forest\n",
    "\n",
    "Now use a [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to predict the labels for the data set. \n",
    "\n",
    "i) use the default values for the parameters to get a RF model running. \n",
    "\n",
    "ii) use 10-fold cross-validation to determine a possibly better choice for the parameter *n_estimators* and *max_features*\n",
    "    \n",
    "iii) select the best-performing decision tree (i.e., the one that achieved the highest cross-validated performance) and report the performance of the fitted model on the held-out test data ?\n",
    "\n",
    "In the report, reflect on how does the test performance of RF compare to the decision tree performance? \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TODO: create 10-fold cross-validation\n",
    "\n",
    "# TODO: set the search space of the parameters\n",
    "\n",
    "# TODO: learn an optimal random forest model\n",
    "\n",
    "# TODO: compute the performance of the model on your held-out test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Outlier Detection - Isolation Forest\n",
    "\n",
    "\n",
    "Use the [Isolation Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) to detect potential outliers in the data set. \n",
    "\n",
    "Again, select two parameters that you would like to investigate and fine-tune (for example, contamination, max_depth, n_estimators, max_samples):\n",
    "\n",
    "i) Perform 10-fold cross-validation and compute the model performance to obtain the optimal model. \n",
    "\n",
    "\n",
    "ii) Compute the accuracy, recall, precision, and F1-score on your held-out test data. \n",
    "\n",
    "\n",
    "\n",
    "#### Tips:\n",
    "\n",
    "- Note that the fit(X) function of the Isolation Forest does not use the labels. \n",
    "\n",
    "\n",
    "- **Look carefully at the values that an Isolation Forest classifier returns. Which value represents the outlier class? Be aware that you need to implement a mapping function f(x) that remaps -1 to 1 and 1 to 0, in order to transform the predictions such that the semantics are consistant with the previous classification algorithms.**\n",
    "\n",
    "\n",
    "- Create 2D or 3D plots to visualize your results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# TODO: set the search space of the parameters\n",
    "\n",
    "# TODO: create 10 fold CV data sets\n",
    "\n",
    "# TODO: learn an optimal Isolation Forest model\n",
    "\n",
    "# TODO: compute the performance of the model on your held-out test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Report your results and discuss your findings\n",
    "\n",
    "By now, you have applied three algorithms with different parameters on the data set. For each algorithm, you have create tables or figures which you can add to your report. Discuss the results and their optimal performance. \n",
    "\n",
    "Create an overview table or figure that show the optimal performance of each algorithm on the data set, for example see the table here below. \n",
    "\n",
    "Discuss your findings and reflect on the following questions:\n",
    "- According to the performance results, which one is the optimal model? \n",
    "- How large is the difference between the accuracy score and the F1 score for each model? What caused the difference?\n",
    "- Would you use the accuracy score, recall, preceision, or F1-score for selecting the model? Why?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Model | CV Accuracy  | Test Accuracy |  CV Recall  |  Test Recall  | CV F1 | Test F1 |... |\n",
    "|------|------|------|------|------|------|------|-----|\n",
    "|   Decision Tree        |  |  | | | | |\n",
    "|   Random Forest  |  |  | || | |\n",
    "|   Isolation Forest        |  |  | || | |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Tasks \n",
    "\n",
    "We would like to challenge you with the following bonus tasks. For each task that is successfully completed, you may obtain max. 1 extra point. \n",
    "\n",
    "1. Implement another outlier detection algorithm or design your own outlier detection algorithm that achieves a better F1 score. \n",
    "2. Implement techniques (e.g., preprocessing, feature engineering, sampling) that help improve the F1 scores of existing models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}